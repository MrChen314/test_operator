# smem_cp_async 精度问题来源及解决方案

## 1. 现象
在 `test_smem_cp_async.py` 的初始版本中，`C_cuda` 与 `C_ref` 偏差较大：
- `random_normal`: `max_abs` 约 `1.885e+01`
- `all_ones`: `max_abs` 约 `1.600e+01`
- `uniform_minus1_1`: `max_abs` 约 `5.208e+00`

## 2. 定位过程与关键证据
为 kernel 增加调试打印后，核心结论如下：

1. `cp.async` 传输长度不是问题  
   日志显示：
   - `logical_B_elems=16384`
   - `storage_B_elems=16384`
   - `cp_async_tx_bytes=32768`
   三者匹配，说明不是“布局有 padding 但只拷贝逻辑长度”导致的问题。

2. `A/B` 数据装载与 peer 交换是正确的  
   对比 `dot(row,col)` 软件点积：
   - `local + peer == ref`
   - `abs_diff=0.0000`
   说明 `sA`、`sB_local`、`sB_peer` 数据本身正确。

3. 错误发生在 MMA 结束到 TMEM 读取阶段  
   初始问题版在 `all_ones` 下出现了典型现象：`C` 中交替出现 `64/48`，而正确值应全为 `64`。这说明有一部分累加尚未在 cluster 内完全可见，就被读取到了。

## 3. 根因
`ku::utcmma_ss(..., WS_SS_NOELECT)` 是跨 2 个 CTA 协作的计算路径。  
原代码在两次 `utcmma_ss` 后只有 `__syncthreads()`（CTA 内同步），缺少必要的 `cluster_sync()`（CTA 间同步）。

结果是：某个 CTA 可能在 peer CTA 完成最终累加前就开始 `store_c_from_tmem`，造成读到未完全收敛的 TMEM 结果，表现为明显精度误差。

## 4. 修复方案
在两次 MMA 之后补齐 cluster 级同步，确保 2 个 CTA 的协作结果都完成后再读 TMEM：

- 第一次 MMA（`clear_accum=true`）后：
  - `ku::tcgen05_after_thread_sync();`
  - `__syncthreads();`
  - `cluster_sync();`  ← 新增

- 第二次 MMA（`clear_accum=false`）后：
  - `ku::tcgen05_after_thread_sync();`
  - `__syncthreads();`
  - `cluster_sync();`  ← 新增

并保留 `store_c_from_tmem` 后的同步，避免后续阶段竞争。

## 5. 修复后验证结果
最新 `bug.txt` 显示三组用例全部通过：

- `random_normal`
  - `max_abs=3.814697e-06`
  - `mean_abs=1.627975e-07`
  - `max_rel=4.807208e-03`
  - `PASS`

- `all_ones`
  - `max_abs=0`
  - `mean_abs=0`
  - `max_rel=0`
  - `PASS`

- `uniform_minus1_1`
  - `max_abs=0`
  - `mean_abs=0`
  - `max_rel=0`
  - `PASS`

- `Overall: PASS`

## 6. 结论
本次精度问题的本质是 **2CTA 协作 MMA 后缺少 cluster 级收敛同步**，不是输入装载或 `cp.async` 传输长度错误。补充 `cluster_sync()` 后，精度恢复并通过全部测试。
